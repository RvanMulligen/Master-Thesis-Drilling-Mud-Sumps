{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-means clustering analysis\n",
        "Created by: Renate van Mulligen\n",
        "\n",
        "In this script the k-means clustering analyses is performed and it is created with the help of the follwing two sites:\n",
        "1. https://towardsdatascience.com/clustering-with-more-than-two-features-try-this-to-explain-your-findings-b053007d680a\n",
        "2. https://realpython.com/k-means-clustering-python/\n",
        "\n",
        "This script consists of 4 parts:\n",
        "1. Installing and importing the used packages\n",
        "2. Opening the data, checking and normalising the data\n",
        "3. Finding the optimal amount of clusters for the clustering analysis\n",
        "4. Performing the cluster analysis and showing the results in a polar plot"
      ],
      "metadata": {
        "id": "i-CbCrRd2u5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installing an importing the used packages\n",
        "In the follwing part, the packeges used in this script are installed and imported. As Google colab doesn't have all the packages used, installation of those packages is necesarry. The package that is installed is kneed. Besides installing, the plotly package used is upgraded. Also, as Google colab uses Google Drive as import and export medium, I connected to my google drive."
      ],
      "metadata": {
        "id": "M-UMlVWX9pBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kneed\n",
        "!pip install --upgrade plotly"
      ],
      "metadata": {
        "id": "xUOjMLM0kGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CwzNe7nbhrti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "lYLo0xbEtzEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount (\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "AGkFYP0CjOVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importing, checking an normalising the data\n",
        "In this section the data is imported from google drive using panda. In preperation for narmalising the data, the name column is removed. Before normalising, the dataset is checked to see if everything is correct and if the name column is removed correclty.\n",
        "\n",
        "When the dataset is correct, than it can be normalised using the MinMax scaler from sklearn. This is done for the cluster analysis and that each variables has the same weight in the analysis. After the normalising, the dataset is checked again to see if everyhing went correctly."
      ],
      "metadata": {
        "id": "X-Jj4-B9_QTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv( r\"/content/gdrive/MyDrive/Master Thesis hydrology/extended_database_river.csv\",delimiter=\";\")\n",
        "X=df.drop(\"Name\", axis=1)"
      ],
      "metadata": {
        "id": "KMtkLey7iQCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "L3Vty9fwiLMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)"
      ],
      "metadata": {
        "id": "HS6eMlE-jChN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "5jlfe2PQAT3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Choosing the optimal number of clusters\n",
        "In the following section, the optimal number of clusters is chosen with two methods:\n",
        "1. The elbow method: in this method the inertia of different numbers of clusters is calculated using k-means package of sklearn and plotted against them. The bending point of the line in the graph is the optimal number of clusters. This bending point is find with the help of kneed.\n",
        "2. The silhoutte coeffiecient: in this method the silhoutte coeffiecient of different number of clusters is calculated using k-means package of sklearn and plotted against them. The number of clusters with the highest silhouette coeffiecient is the optimal number of clusters."
      ],
      "metadata": {
        "id": "SwajKHqaAXCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertia = []\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=i, init=\"k-means++\",\n",
        "    )\n",
        "    kmeans.fit(X)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "fig = go.Figure(data=go.Scatter(x=np.arange(1,11),y=inertia))\n",
        "fig.update_layout(title=\"Inertia vs Cluster Number\",xaxis=dict(range=[0,11],title=\"Cluster Number\"),\n",
        "                  yaxis={'title':'Inertia'},\n",
        "                 )\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "wPgYexmkjhVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kneed import KneeLocator\n",
        "kl = KneeLocator(\n",
        "   range(1, 11), inertia, curve=\"convex\", direction=\"decreasing\"\n",
        ")\n",
        "\n",
        "kl.elbow"
      ],
      "metadata": {
        "id": "pCDwg_OjkD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_coefficients = []\n",
        "for k in range(2, 11):\n",
        "  kmeans = KMeans(n_clusters=k, init=\"k-means++\")\n",
        "  kmeans.fit(X)\n",
        "  score = silhouette_score(X, kmeans.labels_)\n",
        "  silhouette_coefficients.append(score)"
      ],
      "metadata": {
        "id": "PY8V8FQXsxi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.plot(range(2, 11), silhouette_coefficients)\n",
        "plt.xticks(range(2, 11))\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Silhouette Coefficient\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P9GyegDvt7QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. K-means cluster analysis\n",
        "In this part the K-mean clustering analysis is performed.The optimal amount of clusters found in the previous section is used as an input for the clustering analysis. The package us for the k-means clustering analysis is sklearn.  Afterwards, a dataframe is created using pandas in prepartion for export and the creation of a polar plot.\n",
        "\n",
        "Then, the dataset with the assigned clusters to each datapoint is exported to Google Drive and by using plotly, the polar plot, showing the variable mean of each cluster, is created and exported to Google Drive."
      ],
      "metadata": {
        "id": "iRRDk6u_Cc2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "        n_clusters=3, init=\"k-means++\"\n",
        "    )\n",
        "kmeans.fit(X)\n",
        "clusters=pd.DataFrame(X,columns=df.drop(\"Name\",axis=1).columns)\n",
        "clusters['label']=kmeans.labels_\n",
        "\n",
        "polar=clusters.groupby(\"label\").mean().reset_index()\n",
        "polar=pd.melt(polar,id_vars=[\"label\"])"
      ],
      "metadata": {
        "id": "KD4pdoS7-_KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters.to_csv(r\"/content/gdrive/MyDrive/Master Thesis hydrology/extendeddatariverc3-2.csv\",sep=\",\")"
      ],
      "metadata": {
        "id": "uyg91i6kuVkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig4 = px.line_polar(polar, r=\"value\", theta=\"variable\", color=\"label\", line_close=True,height=800,width=1400)\n",
        "fig4.write_html(r\"/content/gdrive/MyDrive/Master Thesis hydrology/extendeddatariverc3-2.csv.html\")\n",
        "fig4.write_image(r\"/content/gdrive/MyDrive/Master Thesis hydrology/extendeddatariverc3-2.csv.png\")\n",
        "fig4.show()"
      ],
      "metadata": {
        "id": "Oa1njixpoP4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}